{
  "hash": "f985af63df1f6b0bd2c9200219113e4e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Time Series Machine Learning\"\nauthor: \"Zahid Asghar\"\nformat: \n  html:\n    toc: true\n    toc_depth: 2\n    number_sections: true\n    toc_float: true\nexecute:\n  freeze: auto\n---\n\n::: {.cell}\n\n:::\n\n\n\nThis vignette covers __Machine Learning for Forecasting__ using the _time-series signature_, a collection calendar features derived from the timestamps in the time series. \n\n# Introduction\n\nThe time series signature is a collection of useful features that describe the time series index of a time-based data set. It contains a wealth of features that can be used to forecast time series that contain patterns.\n\nIn this vignette, the user will learn methods to implement machine learning to predict future outcomes in a time-based data set. The vignette example uses a well known time series dataset, the Bike Sharing Dataset, from the UCI Machine Learning Repository. The vignette follows an example where we'll use `timetk` to build a basic Machine Learning model to predict future values using the time series signature. The objective is to build a model and predict the next six months of Bike Sharing daily counts.  \n\n\n# Prerequisites\n\nBefore we get started, load the following packages.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(timetk)\nlibrary(recipes)\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(rsample)\n# Used to convert plots from interactive to static\ninteractive = FALSE\n```\n:::\n\n\n\n# Data\n\nWe'll be using the [Bike Sharing Dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset) from the UCI Machine Learning Repository.\n\n_Source: Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg_\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Read data\nbike_transactions_tbl <- bike_sharing_daily %>%\n  select(date = dteday, value = cnt)\n\nbike_transactions_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 731 × 2\n   date       value\n   <date>     <dbl>\n 1 2011-01-01   985\n 2 2011-01-02   801\n 3 2011-01-03  1349\n 4 2011-01-04  1562\n 5 2011-01-05  1600\n 6 2011-01-06  1606\n 7 2011-01-07  1510\n 8 2011-01-08   959\n 9 2011-01-09   822\n10 2011-01-10  1321\n# ℹ 721 more rows\n```\n\n\n:::\n:::\n\n\n\nNext, visualize the dataset with the `plot_time_series()` function. Toggle `.interactive = TRUE` to get a plotly interactive plot. `FALSE` returns a ggplot2 static plot. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbike_transactions_tbl %>%\n  plot_time_series(date, value, .interactive = interactive)\n```\n\n::: {.cell-output-display}\n![](Machine_Learning_Forecasting_Using_Time_Series_Signature_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=95%}\n:::\n:::\n\n\n\n# Train / Test \n\nNext, use `time_series_split()` to make a train/test set. \n\n- Setting `assess = \"3 months\"` tells the function to use the last 3-months of data as the testing set. \n- Setting `cumulative = TRUE` tells the sampling to use all of the prior data as the training set. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsplits <- bike_transactions_tbl %>%\n  time_series_split(assess = \"3 months\", cumulative = TRUE)\n```\n:::\n\n\n\nNext, visualize the train/test split. \n\n- `tk_time_series_cv_plan()`: Converts the splits object to a data frame \n- `plot_time_series_cv_plan()`: Plots the time series sampling data using the \"date\" and \"value\" columns. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsplits %>%\n  tk_time_series_cv_plan() %>%\n  plot_time_series_cv_plan(date, value, .interactive = interactive)\n```\n\n::: {.cell-output-display}\n![](Machine_Learning_Forecasting_Using_Time_Series_Signature_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=95%}\n:::\n:::\n\n\n\n# Modeling\n\nMachine learning models are more complex than univariate models (e.g. ARIMA, Exponential Smoothing). This complexity typically requires a ___workflow___ (sometimes called a _pipeline_ in other languages). The general process goes like this:\n\n- __Create Preprocessing Recipe__\n- __Create Model Specifications__\n- __Use Workflow to combine Model Spec and Preprocessing, and Fit Model__\n\n## Recipe Preprocessing Specification\n\nThe first step is to add the _time series signature_ to the training set, which will be used this to learn the patterns. New in `timetk` 0.1.3 is integration with the `recipes` R package:\n\n- The `recipes` package allows us to add preprocessing steps that are applied sequentially as part of a data transformation pipeline. \n\n- The `timetk` has `step_timeseries_signature()`, which is used to add a number of features that can help machine learning models. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(recipes)\n# Add time series signature\nrecipe_spec_timeseries <- recipe(value ~ ., data = training(splits)) %>%\n    step_timeseries_signature(date) \n```\n:::\n\n\n\nWe can see what happens when we apply a prepared recipe `prep()` using the `bake()` function. Many new columns were added from the timestamp \"date\" feature. These are features we can use in our machine learning models. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbake(prep(recipe_spec_timeseries), new_data = training(splits))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 641 × 29\n   date       value date_index.num date_year date_year.iso date_half\n   <date>     <dbl>          <dbl>     <int>         <int>     <int>\n 1 2011-01-01   985     1293840000      2011          2010         1\n 2 2011-01-02   801     1293926400      2011          2010         1\n 3 2011-01-03  1349     1294012800      2011          2011         1\n 4 2011-01-04  1562     1294099200      2011          2011         1\n 5 2011-01-05  1600     1294185600      2011          2011         1\n 6 2011-01-06  1606     1294272000      2011          2011         1\n 7 2011-01-07  1510     1294358400      2011          2011         1\n 8 2011-01-08   959     1294444800      2011          2011         1\n 9 2011-01-09   822     1294531200      2011          2011         1\n10 2011-01-10  1321     1294617600      2011          2011         1\n# ℹ 631 more rows\n# ℹ 23 more variables: date_quarter <int>, date_month <int>,\n#   date_month.xts <int>, date_month.lbl <ord>, date_day <int>,\n#   date_hour <int>, date_minute <int>, date_second <int>, date_hour12 <int>,\n#   date_am.pm <int>, date_wday <int>, date_wday.xts <int>,\n#   date_wday.lbl <ord>, date_mday <int>, date_qday <int>, date_yday <int>,\n#   date_mweek <int>, date_week <int>, date_week.iso <int>, date_week2 <int>, …\n```\n\n\n:::\n:::\n\n\n\nNext, I apply various preprocessing steps to improve the modeling behavior. If you wish to learn more, I have an [Advanced Time Series course](https://mailchi.mp/business-science/time-series-forecasting-course-coming-soon) that will help you learn these techniques.  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrecipe_spec_final <- recipe_spec_timeseries %>%\n    step_fourier(date, period = 365, K = 5) %>%\n    step_rm(date) %>%\n    step_rm(contains(\"iso\"), contains(\"minute\"), contains(\"hour\"),\n            contains(\"am.pm\"), contains(\"xts\")) %>%\n    step_normalize(contains(\"index.num\"), date_year) %>%\n    step_dummy(contains(\"lbl\"), one_hot = TRUE) \n\njuice(prep(recipe_spec_final))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 641 × 47\n   value date_index.num date_year date_half date_quarter date_month date_day\n   <dbl>          <dbl>     <dbl>     <int>        <int>      <int>    <int>\n 1   985          -1.73    -0.869         1            1          1        1\n 2   801          -1.72    -0.869         1            1          1        2\n 3  1349          -1.72    -0.869         1            1          1        3\n 4  1562          -1.71    -0.869         1            1          1        4\n 5  1600          -1.71    -0.869         1            1          1        5\n 6  1606          -1.70    -0.869         1            1          1        6\n 7  1510          -1.70    -0.869         1            1          1        7\n 8   959          -1.69    -0.869         1            1          1        8\n 9   822          -1.68    -0.869         1            1          1        9\n10  1321          -1.68    -0.869         1            1          1       10\n# ℹ 631 more rows\n# ℹ 40 more variables: date_second <int>, date_wday <int>, date_mday <int>,\n#   date_qday <int>, date_yday <int>, date_mweek <int>, date_week <int>,\n#   date_week2 <int>, date_week3 <int>, date_week4 <int>, date_mday7 <int>,\n#   date_sin365_K1 <dbl>, date_cos365_K1 <dbl>, date_sin365_K2 <dbl>,\n#   date_cos365_K2 <dbl>, date_sin365_K3 <dbl>, date_cos365_K3 <dbl>,\n#   date_sin365_K4 <dbl>, date_cos365_K4 <dbl>, date_sin365_K5 <dbl>, …\n```\n\n\n:::\n:::\n\n\n\n\n## Model Specification\n\nNext, let's create a model specification. We'll use a Elastic Net penalized regression via the `glmnet` package. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_spec_lm <- linear_reg(\n    mode = \"regression\", \n    penalty = 0.1\n) %>%\n    set_engine(\"glmnet\")\n```\n:::\n\n\n\n## Workflow\n\nWe can mary up the preprocessing recipe and the model using a `workflow()`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nworkflow_lm <- workflow() %>%\n    add_recipe(recipe_spec_final) %>%\n    add_model(model_spec_lm)\n\nworkflow_lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_timeseries_signature()\n• step_fourier()\n• step_rm()\n• step_rm()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 0.1\n\nComputational engine: glmnet \n```\n\n\n:::\n:::\n\n\n\n## Training\n\nThe workflow can be trained with the `fit()` function. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nif (requireNamespace(\"glmnet\")) {\n  workflow_fit_lm <- workflow_lm %>% fit(data = training(splits))\n}\n```\n:::\n\n\n\n\n## Hyperparameter Tuning\n\nLinear regression has no parameters. Therefore, this step is not needed. More complex models have hyperparameters that require tuning. Algorithms include:\n\n- Elastic Net\n- XGBoost\n- Random Forest\n- Support Vector Machine (SVM)\n- K-Nearest Neighbors\n- Multivariate Adaptive Regression Spines (MARS)\n\nIf you would like to learn how to tune these models for time series, then join the waitlist for my advanced [__Time Series Analysis & Forecasting Course__](https://mailchi.mp/business-science/time-series-forecasting-course-coming-soon).\n\n# Forecasting with Modeltime\n\n__The Modeltime Workflow__ is designed to speed up model evaluation and selection. Now that we have several time series models, let's analyze them and forecast the future with the `modeltime` package. \n\n## Modeltime Table\n\n__The Modeltime Table__ organizes the models with IDs and creates generic descriptions to help us keep track of our models. Let's add the models to a `modeltime_table()`.  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nif (rlang::is_installed(\"modeltime\")) {\n  model_table <- modeltime::modeltime_table(\n  workflow_fit_lm\n) \n\nmodel_table\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Modeltime Table\n# A tibble: 1 × 3\n  .model_id .model     .model_desc\n      <int> <list>     <chr>      \n1         1 <workflow> GLMNET     \n```\n\n\n:::\n:::\n\n\n\n## Calibration\n\n__Model Calibration__ is used to quantify error and estimate confidence intervals. We'll perform model calibration on the out-of-sample data (aka. the Testing Set) with the `modeltime::modeltime_calibrate()` function. Two new columns are generated (\".type\" and \".calibration_data\"), the most important of which is the \".calibration_data\". This includes the actual values, fitted values, and residuals for the testing set. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncalibration_table <- model_table %>%\n  modeltime::modeltime_calibrate(testing(splits))\n\ncalibration_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Modeltime Table\n# A tibble: 1 × 5\n  .model_id .model     .model_desc .type .calibration_data\n      <int> <list>     <chr>       <chr> <list>           \n1         1 <workflow> GLMNET      Test  <tibble [90 × 4]>\n```\n\n\n:::\n:::\n\n\n\n### Forecast (Testing Set)\n\nWith calibrated data, we can visualize the testing predictions (forecast). \n\n- Use `modeltime::modeltime_forecast()` to generate the forecast data for the testing set as a tibble. \n- Use `modeltime::plot_modeltime_forecast()` to visualize the results in interactive and static plot formats.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncalibration_table %>%\n  modeltime::modeltime_forecast(actual_data = bike_transactions_tbl) %>%\n  modeltime::plot_modeltime_forecast(.interactive = interactive)\n```\n\n::: {.cell-output-display}\n![](Machine_Learning_Forecasting_Using_Time_Series_Signature_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=95%}\n:::\n:::\n\n\n\n### Accuracy (Testing Set)\n\nNext, calculate the testing accuracy to compare the models. \n\n- Use `modeltime::modeltime_accuracy()` to generate the out-of-sample accuracy metrics as a tibble.\n- Use `modeltime::table_modeltime_accuracy()` to generate interactive and static \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncalibration_table %>%\n  modeltime::modeltime_accuracy() %>%\n  modeltime::table_modeltime_accuracy(.interactive = interactive)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"dveccinzvy\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#dveccinzvy table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#dveccinzvy thead, #dveccinzvy tbody, #dveccinzvy tfoot, #dveccinzvy tr, #dveccinzvy td, #dveccinzvy th {\n  border-style: none;\n}\n\n#dveccinzvy p {\n  margin: 0;\n  padding: 0;\n}\n\n#dveccinzvy .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#dveccinzvy .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#dveccinzvy .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#dveccinzvy .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#dveccinzvy .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#dveccinzvy .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#dveccinzvy .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#dveccinzvy .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#dveccinzvy .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#dveccinzvy .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#dveccinzvy .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#dveccinzvy .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#dveccinzvy .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#dveccinzvy .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#dveccinzvy .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dveccinzvy .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#dveccinzvy .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#dveccinzvy .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#dveccinzvy .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dveccinzvy .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#dveccinzvy .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dveccinzvy .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#dveccinzvy .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dveccinzvy .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#dveccinzvy .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dveccinzvy .gt_left {\n  text-align: left;\n}\n\n#dveccinzvy .gt_center {\n  text-align: center;\n}\n\n#dveccinzvy .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#dveccinzvy .gt_font_normal {\n  font-weight: normal;\n}\n\n#dveccinzvy .gt_font_bold {\n  font-weight: bold;\n}\n\n#dveccinzvy .gt_font_italic {\n  font-style: italic;\n}\n\n#dveccinzvy .gt_super {\n  font-size: 65%;\n}\n\n#dveccinzvy .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#dveccinzvy .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#dveccinzvy .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#dveccinzvy .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#dveccinzvy .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#dveccinzvy .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#dveccinzvy .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"9\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Accuracy Table</td>\n    </tr>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".model_id\">.model_id</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".model_desc\">.model_desc</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\".type\">.type</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"mae\">mae</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"mape\">mape</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"mase\">mase</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"smape\">smape</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"rmse\">rmse</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"rsq\">rsq</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\".model_id\" class=\"gt_row gt_right\">1</td>\n<td headers=\".model_desc\" class=\"gt_row gt_left\">GLMNET</td>\n<td headers=\".type\" class=\"gt_row gt_left\">Test</td>\n<td headers=\"mae\" class=\"gt_row gt_right\">1244.11</td>\n<td headers=\"mape\" class=\"gt_row gt_right\">331.5</td>\n<td headers=\"mase\" class=\"gt_row gt_right\">1.34</td>\n<td headers=\"smape\" class=\"gt_row gt_right\">29.2</td>\n<td headers=\"rmse\" class=\"gt_row gt_right\">1689.76</td>\n<td headers=\"rsq\" class=\"gt_row gt_right\">0.47</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n## Refit and Forecast Forward\n\n__Refitting__ is a best-practice before forecasting the future. \n\n- `modeltime::modeltime_refit()`: We re-train on full data (`bike_transactions_tbl`)\n- `modeltime::modeltime_forecast()`: For models that only depend on the \"date\" feature, we can use `h` (horizon) to forecast forward. Setting `h = \"12 months\"` forecasts then next 12-months of data. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncalibration_table %>%\n  modeltime::modeltime_refit(bike_transactions_tbl) %>%\n  modeltime::modeltime_forecast(h = \"12 months\", actual_data = bike_transactions_tbl) %>%\n  modeltime::plot_modeltime_forecast(.interactive = interactive)\n```\n\n::: {.cell-output-display}\n![](Machine_Learning_Forecasting_Using_Time_Series_Signature_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=95%}\n:::\n:::\n\n\n\n\n\n# Summary\n\nTimetk is part of the amazing Modeltime Ecosystem for time series forecasting. But it can take a long time to learn: \n\n- Many algorithms\n- Ensembling and Resampling\n- Feature Engineering\n- Machine Learning\n- Deep Learning\n- Scalable Modeling: 10,000+ time series\n\nYour probably thinking how am I ever going to learn time series forecasting. Here's the solution that will save you years of struggling. \n\n\n### Time Series is Changing\n\nTime series is changing. __Businesses now need 10,000+ time series forecasts every day.__ This is what I call a _High-Performance Time Series Forecasting System (HPTSF)_ - Accurate, Robust, and Scalable Forecasting. \n\n __High-Performance Forecasting Systems will save companies by improving accuracy and scalability.__ Imagine what will happen to your career if you can provide your organization a \"High-Performance Time Series Forecasting System\" (HPTSF System).\n\n\n\n- __Time Series Machine Learning__ (cutting-edge) with `Modeltime` - 30+ Models (Prophet, ARIMA, XGBoost, Random Forest, & many more)\n- __Deep Learning__ with `GluonTS` (Competition Winners)\n- __Time Series Preprocessing__, Noise Reduction, & Anomaly Detection\n- __Feature engineering__ using lagged variables & external regressors\n- __Hyperparameter Tuning__\n- __Time series cross-validation__\n- __Ensembling__ Multiple Machine Learning & Univariate Modeling Techniques (Competition Winner)\n- __Scalable Forecasting__ - Forecast 1000+ time series in parallel\n- and more.\n\n<p class=\"text-center\" style=\"font-size:24px;\">\nBecome the Time Series Expert for your organization.\n</p>\n",
    "supporting": [
      "Machine_Learning_Forecasting_Using_Time_Series_Signature_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}