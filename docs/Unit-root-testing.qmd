---
title: "Unit Roots Tests: Methods and Problems"
author: "[[Zahid Asghar, Professor, School of Economics, QAU](https://zahedasghar.netlify.app)]{style=color:blue;}"
date: "today"
format: 
  revealjs:
    theme: [default, custom.css,styles.scss]
    chalkboard: true
    slide-number: c/t
execute:
  echo: false
  warning: false
  freeze: auto
---


```{r}
#| label: setup
#| include: false
library(tidyverse)
library(kableExtra)
library(patchwork)
library(fontawesome)
library(gapminder)
library(scales)

```

# Augmented Dickey-Fuller and Phillips-Perron Unit Roots Tests using R {background-color="#CA225E"}


## Unit Roots Tests 

#### How do you find out if a series is stationary or not?

#### Order of integration of a Series

A series which is stationary after being differenced once is said to integrated of order 1 and is being denoted by *I(1)*. 
In general a series which is stationary after being differenced $d$ times is said to be integrated of order $d$, denoted $I(d)$. A series, which is stationary without differencing, is said to be $I(0)$

$Y_t=b_0+Y_{t-1}+\epsilon_t$ --\> $I(1)$

$\Delta{Y_t}= Y_t-Y_{t-1}=b_0+\epsilon_t$ --\> $I(0)$

## Informal Procedures to indentify non-stationnary process

### Eye ball the data

::: columns
::: {.column width="49%"}
![Constant mean?](images/paste-A7E511A8.png)
:::

::: {.column width="49%"}
![Constant variance?](images/paste-1DFA9EBF.png)
:::
:::

## Diagnostic test - Correlogram

Correlation between 1980 and 1980+K.

For stationary process correlelogram dies out rapidly. Series has no memory. 1980 is not related to 1985.

::: columns
::: {.column width="49%"} 
![stationary](images/paste-4BA97D8D.png)

:::

::: {.column width="49%"}

![non-stationary](images/paste-24AC630E.png)

:::
::: 

## Statistical tests for sationarity: Simple t-test

Set up $AR(1)$ process with drift ($b_0$)

$Y_t = b_0 + bY_{t-1} + \epsilon_t$ where $\epsilon_t \sim \text{iid}(0, \sigma^2)$

Simple approach is to estimate eq(1) using OLS and examine $b$.

-   Use a t-test with null $H_0: b=1$ (non-stationary)

-   against alternative $H_a: b<1$ (stationary)

-   Test Statistics : TS=$(b-1)/SE(b)$ reject null hypothesis when test statistics is large negative 5% critical value is -1.65

## 

Simple t-test based on AR(1) process with drift ($b_0$)

$Y_t=b_0+bY_{t-1}+\epsilon_t \\ \epsilon_t \sim iid(0,\sigma^2)$ --\> (1)



Problem with simple test approach  

1. lagged dependent variables ==\> $b$ biased downwards in small samples (i-e dynamic bias)  

2. When $b=1$, we have non-stationary process and standard regression analysis is invalid (i-e non-standard distribution)

## Dickey Fuller (DF) Test

Subtract $Y_{t-1}$ from both sides of eq(1).

$Y_t-Y_{t-1}=b_0+bY_{t-1}-Y_{t-1}+\epsilon_t \\ \epsilon_t \sim iid(0,\sigma^2)$

$$\Delta{Y_t}= b_0+\beta Y_{t-1}+\epsilon_t \\\beta=b_1-1$$

Use a t-test with: null $H_0: \beta=0$ (non-stationary or **Unit Root**) against alternative $H_0: \beta<0$

-   Large negative test statistics reject non-stationary
-   This is known as unit root test since in eq(1) $H_0: b=0$

## Variants of DF test

The different regression can be used to test the presence of a unit root

$\Delta Y=\beta Y_{t-1}+\epsilon_t$

$\Delta Y=b_0+\beta Y_{t-1}+\epsilon_t$

$\Delta Y=b_0+\beta Y_{t-1}+b_2 t+\epsilon_t$

1.  For testing if Y is a pure Random Walk
2.  For testing if Y is Random Walk with Drift
3.  For testing if Y is a Random walk with Drift and  Deterministi Trend

## {.scrollable}

The simplest model (appropriate **only** if you think there are no other terms present in the *true* regression model)  
$\Delta Y=\beta Y_{t-1}+\epsilon$  

Use the t-statistics and compare it with the table of critical values computed by the DF. If your t value is outside the confidence interval, the null of unit root is rejected.

$\tau$ Statistics

A more general model (allowing for `drift`)

$\Delta Y=b_0+\beta Y_{t-1}+\epsilon$

$\phi_1$ Statistics- Use F statistics if $\beta=b_0=0$ using the non standard tables

$\tau_{\mu}$ Statistics  
- use the t statistics to check if $\beta=0$, against non-standard tables.

## Examples

Sample size of n=25 at 5% level of significance for eq(2)

$\tau$ - critical value=-3.00

t-test critical value=-1.65

$\Delta p_t=-0.007-0.190p_{t-1} \\ (-1.05) (-1.49)$

$\beta=-0.190$ $\tau=-1.49>-3.00$ 

hence cannot reject $H_0$ of unit root.

## Incorporating time trends in DF test for unit root

Some time series clearly display an upward or downward trend (non-stationary mean). Should therefore incorporate trend in the regression used for the DF test.

$\Delta Y=b_0+\beta Y_{t-1}+b_2 trend+\epsilon$ --\>(4) It may be the case that $Y_t$ will be stationary around a trend, although if a trend is not included series is non-stationary.

a.  $H_0=\beta=0 \\H_a:\beta<0$ $\tau \\\Delta Y_t=b_0+\beta Y_{t-1}+b_2 trend+\epsilon$

b.  $H_0=\beta=0 \\H_a:\beta<0$ $\tau_{\mu} \\\Delta Y_t=b_0+\beta Y_{t-1}+\epsilon$

c.  $H_0=\beta=0 \\H_a:\beta<0$ $\tau_{\tau} \\\Delta Y_t=\beta Y_{t-1}+\epsilon$ Critical values from Fuller (1976)

## 

![](images/paste-6A96C572.png)

## Augmented Dickey Fuller (ADF) test for unit root

Dickey Fuller tests assume that the residuals $\epsilon_t$ in the DF regression are non-autocorrelated.

Solution: incorporated lagged dependent variables

For quarterly data add up to four lags $$\Delta Y_t=b_0+\beta Y_{t-1}+\theta_1\Delta Y_{t-1}+\theta_2\Delta Y_{t-2}+\theta_3\Delta Y_{t-3}+\theta_4\Delta Y_{t-4}+\epsilon$$

Problem arises of differentiating between models.\
Use a general to specific approach to eliminate insiginficant variables Check final parsimonious model for autocorrelation.\
Check F-test for significant variables

Use Information Criteria\
Trade-off parsimony vs. residual variance

## 

Conside the following series and its correlogram

![](images/paste-BE1F50D7.png)

The variable Y is clealry trended and question is whether trend : Deterministic or Stochastic



## 

![](images/paste-6268E7CF.png)

## Choose between alternative models - The model-progress results

$$\Delta Y_t=b_0+\beta Y_{t-1}+\theta_1\Delta Y_{t-1}+\theta_2\Delta Y_{t-2}+\theta_3\Delta Y_{t-3}+\theta_4\Delta Y_{t-4}+\epsilon$$ $$\Delta Y_t=b_0+\beta Y_{t-1}+\theta_1\Delta Y_{t-1}+\theta_2\Delta Y_{t-2}+\theta_3\Delta Y_{t-3}+\epsilon$$

$$\Delta Y_t=b_0+\beta Y_{t-1}+\theta_1\Delta Y_{t-1}+\theta_2\Delta Y_{t-2}+\epsilon$$

$$\Delta Y_t=b_0+\beta Y_{t-1}+\theta_1\Delta Y_{t-1}+\epsilon$$

$$\Delta Y_t=b_0+\beta Y_{t-1}+\epsilon$$

AIC, SBC, HQC or some other criteria maybe used beside having judgement for appropriate lag selection.

## ADF vs PP

```{r}
# Load necessary libraries
library(knitr)

# Create the table
comparison_table <- data.frame(
  Feature = c("Underlying Assumption", "Applicability", "Implementation", "Advantages", "Disadvantages"),
  `ADF Test` = c("No serial correlation in error terms", "Data with no significant serial correlation", "Requires lag selection", "Common, well-established test", "Requires attention to serial correlation"),
  `PP Test` = c("No assumptions about serial correlation", "Data with potential serial correlation", "No lag selection required", "More robust to serial correlation", "Less common, may be computationally expensive")
)

# Print the table using kable
kable(comparison_table, caption = "Comparison of ADF Test and PP Test Features")

```


## Choosing ADF or PP

-   If you're confident there's no serial correlation in your data, ADF can be a good choice. 

-   If you suspect serial correlation or are unsure, the PP test is generally recommended for its robustness. 

-   In practice, it's often recommended to run both tests and compare the results. If they agree on the presence or absence of a unit root, you can be more confident in the conclusion.


## 

![](images/paste-E90AFB05.png)


## Three main aspects of Unit root testing

-   Determining components (constant , time trend).

-   ADF test- lag length , use F-test or Schwarz Information Criteria

-   In what sequence should we test?

-   Phi and tau tests

## Three Strategy for Unit Roots

Formal Strategy  

1. Use informal tests- eye ball data and correlogram   


2. Incorporate Time trend if data is upwards trending   


3. Specification of ADF test - how many lags should we incorporate to avoid serial correlation?

## Example 

- Real GDP (2000 Prices) Seasonally Adjusted

1.  Plot Time Series- Non-Stationary (i-e. time varying mean and correlogram non-zero)

![](images/paste-789865AE.png)

## Unit Root Testing

1\) Plot first difference of time series- Stationary

![](images/paste-545C4AD8.png)



# General to Specific or Specific to General Techinque

## Multiple Roots 

$\Delta^2 y_t=b_0+\beta_1 \Delta y_{t-1}+\epsilon_t$

If $\beta_1$ does differ from zero, estimate

$\Delta^2 y_t=b_0+\beta_1 \Delta y_{t-1}+\beta_2 y_{t-1}    +\epsilon_t$

If you reject the null hypothesis $\beta_2$=0, conclude $y_t$ is stationary. 


## Panel Unit Root Tests {.scrollable}

$\Delta y_{it}=b_{io}+\gamma_i y_{it-1}+\sum_{i=1}^n p_i \Delta y_{it-j}+\epsilon_{it}$  

> One way to obtain a more powerful test is to pool the estimates from a number separate series and then test the pooled value. The theory underlying the test is very simple: if you have n independent and unbiased estimates of a parameter, the mean of the estimates is also unbiased. More importantly, so long as the estimates are independent, the central limit theory suggests that the sample mean will be normally distributed around the true mean. 

-     The difficult issue is to correct for cross equation correlation

-   Because the lag lengths can differ across equations, you should perform separate lag length tests for each equation. Moreover, you may choose to exclude the deterministic time trend. However, if the trend is included in one equation, it should be included in all

## Limitations 
-   The null hypothesis for the IPSE test $\gamma_1=\gamma_2=...=\gamma_1=0$. Reject of the null hypothesis means that at least  one of the $\gamma_i's$ differs from zero. 

-   At this point, there is substantial disagreement about the asymptotic theory underlying the test. Sample size can approach infinity by increasing n for a given T, increasing T for a given n, or by simultaneously increasing n and T. 
  -   For small T and large n, the critical values are dependent on the magnitudes of the various $\beta_{ij}$. 
The test requires that that the error terms be serially uncorrelated and contemporaneously uncorrelated. 
You can determine the values of $p_i$ to ensure that the autocorrelations of $\epsilon_{it}$ are zero. Nevertheless, the errors may be contemporaneously correlated in that $E(\epsilon_{it}\epsilon_{jt})\neq 0$
The example above illustrates a common technique to correct for correlation across equations. As in the example, you can subtract a common time effect from each observation. However, there is no assurance that this correction will completely eliminate the correlation. Moreover, it is quite possible that  is nonstationary. Subtracting a nonstationary component from each sequence is clearly at odds with the notion that the variables are stationary. 




