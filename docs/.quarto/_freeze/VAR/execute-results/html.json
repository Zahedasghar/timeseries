{
  "hash": "e4f2526cf908ab54866d7bb056f4a8d3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"[Vector Autoregressions]{.yellow}\"\nauthor: \"Zahid Asghar\"\ndate: \"12 May, 2024\"\nformat:\n  revealjs: \n    slide-number: true\n    chalkboard: true\n    #   buttons: false\n    preview-links: auto\n    theme: [simple, custom.scss]\n    title-slide-attributes: \n      data-background-image: \"https://www.slidekit.com/wp-content/uploads/2023/12/Aesthetic-Google-Slide-Background.jpg\"\nresources:\n  - slides.pdf\n---\n\n\n\n\n\n## Vector Autoregressions (VARs)\n\n**Primary Source: Stock, James H., and Mark W. Watson, \"Vector\nAutoregressions,\" Journal of Economic Perspectives, Vol. 15 No. 4 (Fall\n2001), 101-115.**\n\n*Macroeconometricians do 4 things*\n\n1. Describe and summarize macroeconomic data, \n\n2. [Make macroeconomic forecasts]{.yellow},  \n\n3. Quantify what we know about the true structure of the macroeconomy, \n\n4. [Advise or act as policymakers]{.yellow}. \n\nFollowing the problems of the 1970s, none of the structural models or\nunivariate time series approaches seemed trustworthy. VARs arose in this\nvacuum.\n\n## *VARs come in three varieties:*\n\n\n1. Reduced Form \n\n2. Recursive \n\n3. Structural \n\nA **[reduced-form]{.yellow}** VAR expresses each variable as a linear function of\nits own past values and the past values of all other variables being\nconsidered and a serially uncorrelated error term.\n\n ***\n$\\begin{aligned}\\text{UNEM}_t = \\beta_{10} &+ \\beta_{11}\\text{UNEM}_{t-1} + \\beta_{12}\\text{UNEM}_{t-2}+\\\\ \\gamma_{11}\\text{INFL}_{t-1}& + \\gamma_{12}\\text{INFL}_{t-2} + \\phi_{11}\\text{R}_{t-1} + \\phi_{12}\\text{R}_{t-2}+ \\mu_{1t}\\end{aligned}$\n\n$\\begin{aligned}\\text{INFL}_t = \\beta_{20} &+ \\beta_{21}\\text{UNEM}_{t-1} + \\beta_{22}\\text{UNEM}_{t-2}+ \\\\ \\gamma_{21}\\text{INFL}_{t-1}& + \\gamma_{22}\\text{INFL}_{t-2} + \\phi_{21}\\text{R}_{t-1} + \\phi_{22}\\text{R}_{t-2}+ \\mu_{2t}\\end{aligned}$\n\n$\\begin{aligned}\\text{R}_t = \\beta_{30} &+ \\beta_{31}\\text{UNEM}_{t-1} + \\beta_{32}\\text{UNEM}_{t-2}+\\\\ \\gamma_{31}\\text{INFL}_{t-1}& + \\gamma_{32}\\text{INFL}_{t-2}+ \\phi_{31}\\text{R}_{t-1} + \\phi_{32}\\text{R}_{t-2}+ \\mu_{3t}\\end{aligned}$\n\n ***\nIn theory, the VAR uses all available or relevant past values. In\npractice, frequently the Akaike (AIC) or Bayes (BIC) information\ncriteria are used.\n\nThe error terms are viewed as \"surprises\"---movements in the variables\nafter taking its past into account. If the different variables are\ncorrelated with each other, then the error terms will also be correlated\nacross equations.\n\n## Recursive VAR {.scrollable}\n\nA **recursive VAR** constructs the error terms in each regression to be\nuncorrelated with the error term in the preceding equation. This is done\nby adding carefully- selected contemporaneous values as regressors.\nEstimation of each equation by OLS produces residuals that are\nuncorrelated across equations.\n\n$\\begin{aligned}\\text{UNEM}_t = \\beta_{10} &+ \\beta_{11}\\text{UNEM}_{t-1} + \\beta_{12}\\text{UNEM}_{t-2}+\\\\ \\gamma_{11}\\text{INFL}_{t-1} + \\gamma_{12}\\text{INFL}_{t-2} &+ \\phi_{11}\\text{R}_{t-1} + \\phi_{12}\\text{R}_{t-2}+ \\mu_{1t}\\end{aligned}$\n\n$\\begin{aligned}\\text{INFL}_t = \\beta_{20} &+ \\delta_{21}\\text{UNEM}_{t} + \\beta_{21}\\text{UNEM}_{t-1} +\\\\ \\beta_{22}\\text{UNEM}_{t-2} &+ \\gamma_{21}\\text{INFL}_{t-1} + \\gamma_{22}\\text{INFL}_{t-2}+ \\phi_{21}\\text{R}_{t-1} + \\phi_{22}\\text{R}_{t-2}+ \\mu_{2t}\\end{aligned}$\n\n$\\begin{aligned}\\text{R}_t = \\beta_{30} &+ \\delta_{21}\\text{UNEM}_{t} + \\beta_{31}\\text{UNEM}_{t-1} +\\\\ \\beta_{32}\\text{UNEM}_{t-2}+ \\delta_{31}\\text{INFL}_{t} & +\\gamma_{31}\\text{INFL}_{t-1} + \\gamma_{32}\\text{INFL}_{t-2}+ \\phi_{31}\\text{R}_{t-1} + \\phi_{32}\\text{R}_{t-2}+ \\mu_{3t}\\end{aligned}$\n\nThe recursive VAR amounts to estimating the reduced form, then computing\nthe Cholesky factorization of the reduced form VAR covariance matrix.\n(See the book by Lutkepohl, 1993).\n\nUnfortunately the results depend on the order of the variables. Changing\nthe order changes the VAR equations, coefficients, and residuals, and\nthere are n! recursive VARs possible considering the possible\nreorderings.\n\n## Structural VAR {.scrollable}\n\nA **structural VAR** uses economic theory to sort out contemporaneous\nlinks among the variables. Structural VARs require \"identifying\nassumptions\" that establish causal links among variables. These produce\ninstrumental variables.\n\nStock and Watson offer this example of a structural VAR based on a\nTaylor rule:\n$R_t= r^*+1.5({\\overline \\pi_t - \\pi^*})+1.25({\\overline u_t - u^*})$+\nlagged values of $R_t$,$\\pi_t$,*u*+$\\epsilon_t$\n\nThe asterisked values are desired values and bar values are 4 quarter\ntrailing averages. This equation becomes the interest rate equation in\nthe structural VAR.\n\nFirst the reduced form VAR and a recursive VAR are estimated to\nsummarize the co-movements of the three series involved.\n\nSecond, the reduced form VAR is used to forecast the variables.\n\nThird, the structural VAR is used to estimate the effect of a\npolicy-induced change in the fed funds rate on inflation and\nunemployment.\n\n## Standard practice is to report\n\n### Granger-causality tests\n\n### impulse responses, and\n\n### forecast error variance decompositions.\n\n(These are more informative to understanding the relationships than the\nVAR regression coefficients or $R^2$ statistics.)\n\n## Granger Causality\n\n| Regressor | $\\pi$ | $u$  | $R$  |\n|-----------|-------|------|------|\n| $pi$      | 0.00  | 0.31 | 0.00 |\n| $u$       | 0.02  | 0.00 | 0.00 |\n| $R$       | 0.27  | 0.01 | 0.00 |\n|           |       |      |      |\n\n: Granger-Causality Test : Dependent Variable\n\nThese are p-values for F-statistics for joint tests on lags. So\nunemployment helps predict inflation (2% level), but fed funds does not\nhelp predict inflation (27% level).\n\n## Forecast Variance Error Decomposition\n\nHere is a variance decomposition for the recursive VAR orders as ff, u,\nR. (1960-2000, quarterly). The variance decomposition (forecast error\ndecomposition) is the percentage of the variance of the error made in\nforecasting a variable due to a specific shock at a specific time\nhorizon.\n\n| Forecast Horizon | Fcst SE | $\\pi$ | $u$ | $R$ |\n|------------------|---------|-------|-----|-----|\n| 1                | 0.85    | 2     | 19  | 79  |\n| 4                | 1.84    | 9     | 50  | 41  |\n| 8                | 2.44    | 12    | 60  | 28  |\n| 12               | 2.63    | 16    | 59  | 25  |\n\n: Variance Decomposition of R\n\n## Impulse Response Function {.scrollable}\n\nImpulse responses trace out the response of current and future values of\neach of the variables to a one-unit increase in the current value of one\nof the VAR errors. It is a one-period shock which reverts to zero\nimmediately. These make more sense in the context of a model with\nuncorrelated errors across equations\n\n\n \nIn these we see the effect of a 1% change in each variable as it works\nthrough the recursive VAR system with the coefficients estimated from\nactual data. Also plotted are Â±1 standard deviation error bands,\nyielding roughly 66% confidence intervals.\n\nThe reduced-form VAR model can also be used to iterate forward to\nforecast. Stock and Watson then replace the interest rate equation with\ntwo forms of the Taylor rule (one backward looking and one forward\nlooking), and compare impulse responses of monetary policy shocks.\n\n\n\n## Policy Analysis\n\nTwo type of policies: surprise monetary policy interventions and\nchanging the policy rule, like shifting from a Taylor rule (with weight\non both unemployment and inflation) to explicit inflation targetting\nrule.\n\n## Assessment\n\nVARs are good at capturing co-movements of multiple time series.\nGranger-causality tests, impulse response functions and variance\ndecompositions are well-accepted and widely used. Small VARs have become\nthe benchmarks against which new forecasting systems are judged.\n\nSims (1993) allows for time-varying parameters to capture important\ndrifts in coefficients. Adding variables involves costs. A 9-variable,\nfour lag VAR as 333 unknown coefficients (including intercepts).\nEstimation of all of these requires restrictions. Bayesian approaches\nhave helped control the number of parameters in large VAR models.\n\n------------------------------------------------------------------------\n\nStructural inference is tougher. A lot of the success of these models\ndepends upon evaluation of shocks. VAR shocks reflect omitted variables.\nIf the omitted variables (factors or information) correlate with\nincluded variables, then the estimates will contain omitted variable\nbias. Also, if agents are forward looking, impulse responses may suggest\nbizarre causal responses.\n\nChanging policy rules may lead to misspecification in constant parameter\nstructural VARs just as they might in standard multi-equation structural\nmodels.\n\n## \n\nResearchers also seem to be attempting to rationalize a specific causal\nrelationship in order to be able to justify a 7particular recursive\nordering so that their structural VAR collapses to a recursive VAR,\nwhich makes analysis easier. With regard to forecast error variances,\nSpencer (JMCB, 1989), finds: Ordering of variables: ordering of the\nvariables is critically important. It is of greater importance for\ntemporally aggregated data since the contemporaneous correlation of the\npre-orthogonalized aggregated data is likely to be greater. There is\nless problem for monthly data than for quarterly, semi-annual, and\nannual data. \n\n *** \n \nTrend removal: the method of detrending can make a substantial\ndifference to variance decomposition results. Lag length: In a [`mrpy`]{.yellow}\nmodel, a second year of lags to the VAR gives increased estimates of the\nimportance of money in explaining industrial production. Adding lags\nalso seems to improve the stability of results across orderings. Level\nof temporal aggregation: While aggregation may reduce noise in series,\nit increases cont. correlation.\n\n1",
    "supporting": [
      "VAR_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}