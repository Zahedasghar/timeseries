{
  "hash": "913a667540c49f1dcb1c4309fbb421f2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Vector Autoregressions\"\nauthor: \"Zahid Asghar\"\ndate: \"13 May, 2024\"\nformat:\n  revealjs: \n    slide-number: true\n    # chalkboard: \n    #   buttons: false\n    preview-links: auto\n    theme: [simple, custom.scss]\n    #title-slide-attributes:\n      #data-background-color: \"#495efc\"\nresources:\n  - slides.pdf\n---\n\n\n\n\n\n## Vector Autoregressions (VARs) \n\n**Primary Source: Stock, James H., and Mark W. Watson, “Vector Autoregressions,” Journal of Economic Perspectives, Vol. 15 No. 4 (Fall 2001), 101-115.**\n\n_Macroeconometricians do 4 things_ \n\n    1. Describe and summarize macroeconomic data, \n\n    2. Make macroeconomic forecasts,  \n\n    3. Quantify what we know about the true structure of the macroeconomy, \n\n    4. Advise or act as policymakers. \n\n   Following the problems of the 1970s, none of the structural models or univariate time series approaches seemed trustworthy. VARs arose in this vacuum. \n\n## _VARs come in three varieties:_ \n\n     1. Reduced Form \n\n     2. Recursive \n\n     3. Structural \n\n  A __reduced-form__ VAR expresses each variable as a linear function of its own past values and the past values of all other variables being considered and a serially uncorrelated error term.\n  \n  ***\n  \n  $\\begin{aligned}\\text{UNEM}_t = \\beta_{10} &+ \\beta_{11}\\text{UNEM}_{t-1} + \\beta_{12}\\text{UNEM}_{t-2}+ \\gamma_{11}\\text{INFL}_{t-1}\\\\& + \\gamma_{12}\\text{INFL}_{t-2} + \\phi_{11}\\text{R}_{t-1} + \\phi_{12}\\text{R}_{t-2}+ \\mu_{1t}\\end{aligned}$ \n    \n  $\\begin{aligned}\\text{INFL}_t = \\beta_{20} &+ \\beta_{21}\\text{UNEM}_{t-1} + \\beta_{22}\\text{UNEM}_{t-2}+ \\gamma_{21}\\text{INFL}_{t-1}\\\\& + \\gamma_{22}\\text{INFL}_{t-2} + \\phi_{21}\\text{R}_{t-1} + \\phi_{22}\\text{R}_{t-2}+ \\mu_{2t}\\end{aligned}$\n    \n  $\\begin{aligned}\\text{R}_t = \\beta_{30} &+ \\beta_{31}\\text{UNEM}_{t-1} + \\beta_{32}\\text{UNEM}_{t-2}+ \\gamma_{31}\\text{INFL}_{t-1}\\\\& + \\gamma_{32}\\text{INFL}_{t-2}+ \\phi_{31}\\text{R}_{t-1} + \\phi_{32}\\text{R}_{t-2}+ \\mu_{3t}\\end{aligned}$\n  \n  ***\n  \n  In theory, the VAR uses all available or relevant past values. In practice, frequently the Akaike (AIC) or Bayes (BIC) information criteria are used. \n  \n  The error terms are viewed as “surprises”—movements in the variables after taking its past into account. If the different variables are correlated with each other, then the error terms will also be correlated across equations. \n\n *** \n \n  A __recursive VAR__ constructs the error terms in each regression to be uncorrelated with the error term in the preceding equation. This is done by adding carefully- selected contemporaneous values as regressors. Estimation of each equation by OLS produces residuals that are uncorrelated across equations. \n  \n  $\\begin{aligned}\\text{UNEM}_t = \\beta_{10} &+ \\beta_{11}\\text{UNEM}_{t-1} + \\beta_{12}\\text{UNEM}_{t-2}+ \\gamma_{11}\\text{INFL}_{t-1} + \\gamma_{12}\\text{INFL}_{t-2}\\\\ &+ \\phi_{11}\\text{R}_{t-1} + \\phi_{12}\\text{R}_{t-2}+ \\mu_{1t}\\end{aligned}$\n  \n  $\\begin{aligned}\\text{INFL}_t = \\beta_{20} &+ \\delta_{21}\\text{UNEM}_{t} + \\beta_{21}\\text{UNEM}_{t-1} + \\beta_{22}\\text{UNEM}_{t-2}\\\\ &+ \\gamma_{21}\\text{INFL}_{t-1} + \\gamma_{22}\\text{INFL}_{t-2}+ \\phi_{21}\\text{R}_{t-1} + \\phi_{22}\\text{R}_{t-2}+ \\mu_{2t}\\end{aligned}$\n  \n $\\begin{aligned}\\text{R}_t = \\beta_{30} &+ \\delta_{21}\\text{UNEM}_{t} + \\beta_{31}\\text{UNEM}_{t-1} + \\beta_{32}\\text{UNEM}_{t-2}+ \\delta_{31}\\text{INFL}_{t}\\\\ & +\\gamma_{31}\\text{INFL}_{t-1} + \\gamma_{32}\\text{INFL}_{t-2}+ \\phi_{31}\\text{R}_{t-1} + \\phi_{32}\\text{R}_{t-2}+ \\mu_{3t}\\end{aligned}$ \n \n The recursive VAR amounts to estimating the reduced form, then computing the Cholesky factorization of the reduced form VAR covariance matrix. (See the book by Lutkepohl, 1993). \n\n  *** \n  \n  Unfortunately the results depend on the order of the variables. Changing the order changes the VAR equations, coefficients, and residuals, and there are n! recursive VARs possible considering the possible reorderings. \n  \n  A __structural VAR__ uses economic theory to sort out contemporaneous links among the variables. Structural VARs require “identifying assumptions” that establish causal links among variables. These produce instrumental variables.\n  \n  Stock and Watson offer this example of a structural VAR \nbased on a Taylor rule: \n$R_t= r^*+1.5({\\overline \\pi_t - \\pi^*})+1.25({\\overline u_t - u^*})$+ lagged values of $R_t$,$\\pi_t$,_u_+$\\epsilon_t$ \n\nThe asterisked values are desired values and bar values are 4 quarter trailing averages. This equation becomes the  interest rate equation in the structural VAR. \n\n  First the reduced form VAR and a recursive VAR are estimated to summarize the co-movements of the three series involved. \n  \n Second, the reduced form VAR is used to forecast the variables. \n \n ***\n \n Third, the structural VAR is used to estimate the effect of a policy-induced change in the fed funds rate on inflation and unemployment. \n    \n  __Standard practice__ is to report \n  \n    Granger-causality tests\n    \n    impulse responses, and \n    \n    forecast error variance decompositions. \n    \n(These are more informative to understanding the relationships than the VAR regression coefficients or $R^2$  statistics.) \n\n## Granger Causality \n\n  ![](/Users/hp/Documents/granger.png) \n\n## Forecast Variance Error Deceomposition  \n  \n  ![](/Users/hp/Documents/vardecomp.png)\n\n## Impulse Response Function \n\n![](/Users/hp/Documents/irf.png) \n\n  In these we see the effect of a 1% change in each variable as it works through the recursive VAR system with the coefficients estimated from actual data. Also plotted are ±1 standard deviation error bands, yielding roughly 66% confidence intervals. \n  \n  The reduced-form VAR model can also be used to iterate forward to forecast. Stock and Watson then replace the interest rate equation with two forms of the Taylor rule (one backward looking and one forward looking), and compare impulse responses of monetary policy shocks. \n\n## Forecasting \n\n  ![](/Users/hp/Documents/forecast.png) \n  \n## Structural Inference \n\n![](/Users/hp/Documents/fig2_jep.png) \n\n## Policy Analysis \n\n Two type of policies: surprise monetary policy interventions and changing the policy rule, like shifting from a Taylor rule  (with weight on both unemployment and inflation) to explicit inflation targetting rule.\n   \n## Assessment \n\nVARs are good at capturing co-movements of multiple time series. Granger-causality tests, impulse response functions and variance decompositions are well-accepted and widely used. \nSmall VARs have become the benchmarks against which new forecasting systems are judged. \n\n  Sims (1993) allows for time-varying parameters to capture important drifts in coefficients. Adding variables involves costs. A 9-variable, four lag VAR as 333 unknown coefficients (including intercepts). Estimation of all of these requires restrictions. Bayesian approaches have helped control the number of parameters in large VAR models. \n  \n  ***\n  \n  Structural inference is tougher. A lot of the success of these models depends upon evaluation of shocks. VAR shocks reflect omitted variables. If the omitted variables (factors or information) correlate with included variables, then the estimates will contain omitted variable bias. Also, if agents are forward looking, impulse responses may suggest bizarre causal responses. \n \n  Changing policy rules may lead to misspecification in constant parameter structural VARs just as they might in standard multi-equation structural models. \n  \n  ***\n  \n  Researchers also seem to be attempting to rationalize a specific causal relationship in order to be able to justify a 7particular recursive ordering so that their structural VAR \ncollapses to a recursive VAR, which makes analysis easier. With regard to forecast error variances, Spencer (JMCB, 1989), finds: \n  Ordering of variables: ordering of the variables is critically important. It is of greater importance for temporally aggregated data since the contemporaneous correlation of the pre-orthogonalized aggregated data is likely to be greater. There is less problem for monthly data than for quarterly, semi-annual, and annual data. \n  \n  Trend removal: the method of detrending can make a substantial difference to variance decomposition results. Lag length: In a mrpy model, a second year of lags to the \n\n  VAR gives increased estimates of the importance of money in explaining industrial production. Adding lags also seems to improve the stability of results across orderings. \nLevel of temporal aggregation: While aggregation may reduce noise in series, it increases cont. correlation. \n  \n  \n  \n  \n  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}